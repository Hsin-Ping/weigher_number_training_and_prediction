{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "#step1 : check the dataset shape -> ok\n",
    "data = glob.glob('./dataset/crop/*.jpg')\n",
    "for i in data:\n",
    "    img = cv2.imread(i,0)# read the data as 1 channel\n",
    "    print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103.124.74.8_7105_2022-03-29-21-06-37.jpg_0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103.124.74.8_7105_2022-03-29-21-16-37.jpg_0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103.124.74.8_7105_2022-03-29-21-26-37.jpg_0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103.124.74.8_7105_2022-03-29-21-36-38.jpg_0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103.124.74.8_7105_2022-03-29-21-56-38.jpg_0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>103.124.74.8_7105_2022-03-31-00-08-50.jpg_0.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>103.124.74.8_7105_2022-03-31-00-08-50.jpg_1.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>103.124.74.8_7105_2022-03-31-00-08-50.jpg_2.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>103.124.74.8_7105_2022-03-31-00-09-07.jpg_0.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>103.124.74.8_7105_2022-03-31-00-09-19.jpg_0.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0    103.124.74.8_7105_2022-03-29-21-06-37.jpg_0.jpg  1\n",
       "1    103.124.74.8_7105_2022-03-29-21-16-37.jpg_0.jpg  1\n",
       "2    103.124.74.8_7105_2022-03-29-21-26-37.jpg_0.jpg  1\n",
       "3    103.124.74.8_7105_2022-03-29-21-36-38.jpg_0.jpg  1\n",
       "4    103.124.74.8_7105_2022-03-29-21-56-38.jpg_0.jpg  1\n",
       "..                                               ... ..\n",
       "535  103.124.74.8_7105_2022-03-31-00-08-50.jpg_0.jpg  1\n",
       "536  103.124.74.8_7105_2022-03-31-00-08-50.jpg_1.jpg  5\n",
       "537  103.124.74.8_7105_2022-03-31-00-08-50.jpg_2.jpg  6\n",
       "538  103.124.74.8_7105_2022-03-31-00-09-07.jpg_0.jpg  9\n",
       "539  103.124.74.8_7105_2022-03-31-00-09-19.jpg_0.jpg  3\n",
       "\n",
       "[540 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step2 : read the csv file\n",
    "df = pd.read_csv('./dataset/label_crop.csv',header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]] 5\n"
     ]
    }
   ],
   "source": [
    "# 載入 MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_train[0],y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.uint8'>\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train[0]))\n",
    "print(x_train[0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.tolist()\n",
    "y_train = y_train.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60540, 28, 28)\n",
      "(60540,)\n",
      "<class 'numpy.uint8'>\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "# add new data to x_train , y_train\n",
    "for data,label in zip(df[0],df[1]):\n",
    "    img_path = f'./dataset/crop/{data}'\n",
    "    img = cv2.imread(img_path,0)\n",
    "    x_train.append(img)\n",
    "    y_train.append(label)\n",
    "x_train = np.array(x_train,dtype=np.uint8)\n",
    "y_train = np.array(y_train,dtype=np.uint8)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(type(y_train[-1]))\n",
    "print(x_train[-1].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   2   0   0   1   0   1   1   0   0\n",
      "    2   0   0   1   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   3   2   0   5   0   0   4   0\n",
      "    0   1   2   0   2   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   2   0   1   3   0   0   0   0   2\n",
      "    0   2   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0   4   7  30  28  34  33  21   1\n",
      "    0   0   2   6   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   3 150 255 255 252 255 224 178\n",
      "  176 142   5   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   2  18 252 255 254 255 255 255 254\n",
      "  255 255 129   0   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  13 255 255 255 255 254 255 251\n",
      "  255 255 138   2   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0   7  82  81  81  84 157 190 255\n",
      "  253 254 147   0   1   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   2   0 243\n",
      "  254 253 143   1   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   4   0   2   0   0  52 242\n",
      "  255 255  37   1   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0  95 255\n",
      "  255 201   8   0   4   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0 138 255\n",
      "  255 176   0   4   1   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   6 111 127 126 126 130 128 203 254 254\n",
      "  255  73   0   2   0   3   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  86 255 255 255 255 254 254 255 255 254\n",
      "  225  25   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 175 255 254 252 255 255 255 251 255 255\n",
      "  206   0   2   1   0   4   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  89 218 239 242 237 236 243 248 255 253\n",
      "  154   0   0   1   2   0   0   0   0   0]\n",
      " [  1   0   1   0   2   1   0   1   2   0   2   0   0   0   0 174 255 255\n",
      "   94   0   5   0   0   0   0   0   0   0]\n",
      " [  0   0   0   2   0   2   0   0   0   0   1   0   2   0  26 238 255 254\n",
      "   98   1   0   0   0   3   0   0   0   0]\n",
      " [  0   1   1   0   0   1   0   4   2   2   0   0   0   3  33 255 254 243\n",
      "   10   0   2   3   0   0   0   0   0   0]\n",
      " [  0   0   2   0   2   3   1   0   0   0   0   1   0   0 102 254 254 240\n",
      "    0   1   0   0   0   2   0   0   0   0]\n",
      " [  1   0   0   1   1   0   3   1  59  82  83  83  84  80 178 255 255 155\n",
      "    0   3   0   0   2   0   0   0   0   0]\n",
      " [  2   0   0   1   0   0   0  80 243 255 251 252 255 255 254 255 255 126\n",
      "    0   4   0   3   0   1   0   0   0   0]\n",
      " [  0   0   2   0   1   4   1 142 255 255 255 255 255 251 255 252 239  11\n",
      "    0   0   0   0   2   0   0   0   0   0]\n",
      " [  1   0   0   0   1   0   0 109 255 253 254 255 253 224 175 178  60   3\n",
      "    0   1   1   1   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   1   2  32  30  31  34  29  16   4   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   1   1   2   0   0   1   2   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   2   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   1   1   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# check the last data -> img and label are both 3\n",
    "print(x_train[-1])\n",
    "print(y_train[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 20m 57s]\n",
      "val_loss: 0.038465023040771484\n",
      "\n",
      "Best val_loss So Far: 0.038465023040771484\n",
      "Total elapsed time: 00h 20m 57s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/20\n",
      "1892/1892 [==============================] - 82s 43ms/step - loss: 0.1601 - accuracy: 0.9511\n",
      "Epoch 2/20\n",
      "1892/1892 [==============================] - 75s 40ms/step - loss: 0.0737 - accuracy: 0.9770\n",
      "Epoch 3/20\n",
      "1892/1892 [==============================] - 73s 39ms/step - loss: 0.0586 - accuracy: 0.9820\n",
      "Epoch 4/20\n",
      "1892/1892 [==============================] - 93s 49ms/step - loss: 0.0492 - accuracy: 0.98480s - loss: 0.049\n",
      "Epoch 5/20\n",
      "1892/1892 [==============================] - 87s 46ms/step - loss: 0.0458 - accuracy: 0.9860\n",
      "Epoch 6/20\n",
      "1892/1892 [==============================] - 94s 50ms/step - loss: 0.0416 - accuracy: 0.9868\n",
      "Epoch 7/20\n",
      "1892/1892 [==============================] - 94s 49ms/step - loss: 0.0370 - accuracy: 0.9880\n",
      "Epoch 8/20\n",
      "1892/1892 [==============================] - 91s 48ms/step - loss: 0.0352 - accuracy: 0.9888\n",
      "Epoch 9/20\n",
      "1892/1892 [==============================] - 80s 42ms/step - loss: 0.0323 - accuracy: 0.9892\n",
      "Epoch 10/20\n",
      "1892/1892 [==============================] - 74s 39ms/step - loss: 0.0299 - accuracy: 0.9898\n",
      "Epoch 11/20\n",
      "1892/1892 [==============================] - 81s 43ms/step - loss: 0.0305 - accuracy: 0.9899\n",
      "Epoch 12/20\n",
      "1892/1892 [==============================] - 79s 42ms/step - loss: 0.0261 - accuracy: 0.9916\n",
      "Epoch 13/20\n",
      "1892/1892 [==============================] - 89s 47ms/step - loss: 0.0255 - accuracy: 0.9915\n",
      "Epoch 14/20\n",
      "1892/1892 [==============================] - 81s 43ms/step - loss: 0.0265 - accuracy: 0.9910\n",
      "Epoch 15/20\n",
      "1892/1892 [==============================] - 80s 42ms/step - loss: 0.0240 - accuracy: 0.9919\n",
      "Epoch 16/20\n",
      "1892/1892 [==============================] - 77s 41ms/step - loss: 0.0216 - accuracy: 0.9929\n",
      "Epoch 17/20\n",
      "1892/1892 [==============================] - 76s 40ms/step - loss: 0.0219 - accuracy: 0.9928\n",
      "Epoch 18/20\n",
      "1892/1892 [==============================] - 86s 46ms/step - loss: 0.0220 - accuracy: 0.9926\n",
      "Epoch 19/20\n",
      "1892/1892 [==============================] - 77s 41ms/step - loss: 0.0210 - accuracy: 0.9929\n",
      "Epoch 20/20\n",
      "1892/1892 [==============================] - 75s 40ms/step - loss: 0.0214 - accuracy: 0.9929\n",
      "INFO:tensorflow:Assets written to: ./image_classifier/best_model/assets\n",
      "313/313 [==============================] - 3s 8ms/step - loss: 0.0363 - accuracy: 0.9895\n",
      "\n",
      "Prediction loss: 0.036, accurcy: 98.950%\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "cast_to_float32 (CastToFloat (None, 28, 28)            0         \n",
      "_________________________________________________________________\n",
      "expand_last_dim (ExpandLastD (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 28, 28, 1)         3         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                92170     \n",
      "_________________________________________________________________\n",
      "classification_head_1 (Softm (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 110,989\n",
      "Trainable params: 110,986\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: ./mnist_model/assets\n",
      "INFO:tensorflow:Assets written to: /var/folders/v9/r30km26x1xx13fqkq7t5w0b40000gn/T/tmp6aa14sks/assets\n",
      "WARNING:tensorflow:Issue encountered when serializing table_initializer.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'NoneType' object has no attribute 'name'\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "TF_LITE_MODEL = './mnist.tflite'  # 要產生的 TF Lite 檔名\n",
    "SAVE_KERAS_MODEL = True  # 是否儲存 Keras 原始模型\n",
    "import autokeras as ak\n",
    "import tensorflow as tf\n",
    "# 訓練 AutoKeras 模型\n",
    "clf = ak.ImageClassifier(max_trials=1, overwrite=True)\n",
    "clf.fit(x_train, y_train, epochs=20)\n",
    "# 用測試集評估模型\n",
    "loss, accuracy = clf.evaluate(x_test, y_test)\n",
    "print(f'\\nPrediction loss: {loss:.3f}, accurcy: {accuracy*100:.3f}%\\n')\n",
    "# 匯出 Keras 模型\n",
    "model = clf.export_model()\n",
    "model.summary()\n",
    "# 儲存 Keras 模型\n",
    "if SAVE_KERAS_MODEL:\n",
    "    model.save('./mnist_model')\n",
    "# 將模型轉為 TF Lite 格式\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# 你也可以讀取已儲存的 Keras 模型來轉換：\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model('./mnist_model')\n",
    "tflite_model = converter.convert()\n",
    "# 儲存 TF Lite 模型\n",
    "with open(TF_LITE_MODEL, 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
