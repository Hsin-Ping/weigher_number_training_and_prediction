{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "#step1 : check the dataset shape -> ok\n",
    "data = glob.glob('./dataset/crop/*.jpg')\n",
    "for i in data:\n",
    "    img = cv2.imread(i,0)# read the data as 1 channel\n",
    "    print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step2 : read the csv file\n",
    "df = pd.read_csv('./dataset/label_crop.csv')\n",
    "df.columns = [\"Y\",\"X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]] 5\n"
     ]
    }
   ],
   "source": [
    "# 載入 MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_train[0],y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60540, 28, 28)\n",
      "(60540,)\n",
      "<class 'numpy.uint8'>\n",
      "uint8\n"
     ]
    }
   ],
   "source": [
    "# add new data to x_train , y_train\n",
    "x_train = x_train.tolist()\n",
    "y_train = y_train.tolist()\n",
    "for idx in range(len(df)):\n",
    "    img_path = f'./dataset/crop/{df.iloc[idx][\"Y\"]}'\n",
    "    label = df.iloc[idx][\"X\"]\n",
    "    img = cv2.imread(img_path,0)\n",
    "    x_train.append(img)\n",
    "    y_train.append(label)\n",
    "x_train = np.array(x_train,dtype=np.uint8)\n",
    "y_train = np.array(y_train,dtype=np.uint8)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(type(y_train[-1]))\n",
    "print(x_train[-1].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   2   0   0   1   0   1   1   0   0\n",
      "    2   0   0   1   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   3   2   0   5   0   0   4   0\n",
      "    0   1   2   0   2   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   2   0   1   3   0   0   0   0   2\n",
      "    0   2   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0   4   7  30  28  34  33  21   1\n",
      "    0   0   2   6   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   3 150 255 255 252 255 224 178\n",
      "  176 142   5   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   2  18 252 255 254 255 255 255 254\n",
      "  255 255 129   0   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  13 255 255 255 255 254 255 251\n",
      "  255 255 138   2   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0   7  82  81  81  84 157 190 255\n",
      "  253 254 147   0   1   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   2   0 243\n",
      "  254 253 143   1   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   4   0   2   0   0  52 242\n",
      "  255 255  37   1   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0  95 255\n",
      "  255 201   8   0   4   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   5   0   0   0   0 138 255\n",
      "  255 176   0   4   1   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   6 111 127 126 126 130 128 203 254 254\n",
      "  255  73   0   2   0   3   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  86 255 255 255 255 254 254 255 255 254\n",
      "  225  25   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 175 255 254 252 255 255 255 251 255 255\n",
      "  206   0   2   1   0   4   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  89 218 239 242 237 236 243 248 255 253\n",
      "  154   0   0   1   2   0   0   0   0   0]\n",
      " [  1   0   1   0   2   1   0   1   2   0   2   0   0   0   0 174 255 255\n",
      "   94   0   5   0   0   0   0   0   0   0]\n",
      " [  0   0   0   2   0   2   0   0   0   0   1   0   2   0  26 238 255 254\n",
      "   98   1   0   0   0   3   0   0   0   0]\n",
      " [  0   1   1   0   0   1   0   4   2   2   0   0   0   3  33 255 254 243\n",
      "   10   0   2   3   0   0   0   0   0   0]\n",
      " [  0   0   2   0   2   3   1   0   0   0   0   1   0   0 102 254 254 240\n",
      "    0   1   0   0   0   2   0   0   0   0]\n",
      " [  1   0   0   1   1   0   3   1  59  82  83  83  84  80 178 255 255 155\n",
      "    0   3   0   0   2   0   0   0   0   0]\n",
      " [  2   0   0   1   0   0   0  80 243 255 251 252 255 255 254 255 255 126\n",
      "    0   4   0   3   0   1   0   0   0   0]\n",
      " [  0   0   2   0   1   4   1 142 255 255 255 255 255 251 255 252 239  11\n",
      "    0   0   0   0   2   0   0   0   0   0]\n",
      " [  1   0   0   0   1   0   0 109 255 253 254 255 253 224 175 178  60   3\n",
      "    0   1   1   1   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   1   2  32  30  31  34  29  16   4   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   1   1   2   0   0   1   2   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   2   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   1   1   1   1   1   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# check the last data -> img and label are both 3\n",
    "print(x_train[-1])\n",
    "print(y_train[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 08m 28s]\n",
      "val_loss: 0.04421831667423248\n",
      "\n",
      "Best val_loss So Far: 0.04421831667423248\n",
      "Total elapsed time: 00h 08m 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1892/1892 [==============================] - 31s 16ms/step - loss: 0.1566 - accuracy: 0.9523\n",
      "Epoch 2/20\n",
      "1892/1892 [==============================] - 30s 16ms/step - loss: 0.0728 - accuracy: 0.9772\n",
      "Epoch 3/20\n",
      "1892/1892 [==============================] - 30s 16ms/step - loss: 0.0588 - accuracy: 0.9816\n",
      "Epoch 4/20\n",
      "1892/1892 [==============================] - 30s 16ms/step - loss: 0.0490 - accuracy: 0.9846\n",
      "Epoch 5/20\n",
      "1892/1892 [==============================] - 31s 16ms/step - loss: 0.0447 - accuracy: 0.9857\n",
      "Epoch 6/20\n",
      "1892/1892 [==============================] - 31s 16ms/step - loss: 0.0409 - accuracy: 0.9871\n",
      "Epoch 7/20\n",
      "1892/1892 [==============================] - 33s 17ms/step - loss: 0.0369 - accuracy: 0.9880\n",
      "Epoch 8/20\n",
      "1892/1892 [==============================] - 31s 16ms/step - loss: 0.0344 - accuracy: 0.9892\n",
      "Epoch 9/20\n",
      "1892/1892 [==============================] - 32s 17ms/step - loss: 0.0309 - accuracy: 0.9896\n",
      "Epoch 10/20\n",
      "1892/1892 [==============================] - 31s 16ms/step - loss: 0.0298 - accuracy: 0.9908\n",
      "Epoch 11/20\n",
      "1892/1892 [==============================] - 31s 16ms/step - loss: 0.0286 - accuracy: 0.9909\n",
      "Epoch 12/20\n",
      "1892/1892 [==============================] - 31s 16ms/step - loss: 0.0277 - accuracy: 0.9911\n",
      "Epoch 13/20\n",
      "1892/1892 [==============================] - 31s 16ms/step - loss: 0.0266 - accuracy: 0.9916\n",
      "Epoch 14/20\n",
      "1892/1892 [==============================] - 31s 16ms/step - loss: 0.0250 - accuracy: 0.9917\n",
      "Epoch 15/20\n",
      "1892/1892 [==============================] - 32s 17ms/step - loss: 0.0248 - accuracy: 0.9921\n",
      "Epoch 16/20\n",
      "1892/1892 [==============================] - 33s 18ms/step - loss: 0.0215 - accuracy: 0.9926\n",
      "Epoch 17/20\n",
      "1892/1892 [==============================] - 37s 19ms/step - loss: 0.0222 - accuracy: 0.9926\n",
      "Epoch 18/20\n",
      "1892/1892 [==============================] - 34s 18ms/step - loss: 0.0221 - accuracy: 0.9924\n",
      "Epoch 19/20\n",
      "1892/1892 [==============================] - 32s 17ms/step - loss: 0.0217 - accuracy: 0.9926\n",
      "Epoch 20/20\n",
      "1892/1892 [==============================] - 32s 17ms/step - loss: 0.0211 - accuracy: 0.9931\n",
      "INFO:tensorflow:Assets written to: ./image_classifier/best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./image_classifier/best_model/assets\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0362 - accuracy: 0.9896\n",
      "\n",
      "Prediction loss: 0.036, accurcy: 98.960%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " cast_to_float32 (CastToFlo  (None, 28, 28)            0         \n",
      " at32)                                                           \n",
      "                                                                 \n",
      " expand_last_dim (ExpandLas  (None, 28, 28, 1)         0         \n",
      " tDim)                                                           \n",
      "                                                                 \n",
      " normalization (Normalizati  (None, 28, 28, 1)         3         \n",
      " on)                                                             \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 12, 12, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                92170     \n",
      "                                                                 \n",
      " classification_head_1 (Sof  (None, 10)                0         \n",
      " tmax)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 110989 (433.55 KB)\n",
      "Trainable params: 110986 (433.54 KB)\n",
      "Non-trainable params: 3 (16.00 Byte)\n",
      "_________________________________________________________________\n",
      "INFO:tensorflow:Assets written to: ./mnist_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./mnist_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/9_/7d9745rx1nl777112h0zs4240000gn/T/tmpkkt8g54q/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/9_/7d9745rx1nl777112h0zs4240000gn/T/tmpkkt8g54q/assets\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "2024-01-23 14:41:35.109947: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-23 14:41:35.110391: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-23 14:41:35.118264: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/9_/7d9745rx1nl777112h0zs4240000gn/T/tmpkkt8g54q\n",
      "2024-01-23 14:41:35.118956: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-23 14:41:35.118961: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/9_/7d9745rx1nl777112h0zs4240000gn/T/tmpkkt8g54q\n",
      "2024-01-23 14:41:35.127897: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-01-23 14:41:35.128275: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-23 14:41:35.145496: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/9_/7d9745rx1nl777112h0zs4240000gn/T/tmpkkt8g54q\n",
      "2024-01-23 14:41:35.149770: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 31506 microseconds.\n",
      "2024-01-23 14:41:35.174678: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 8, Total Ops 19, % non-converted = 42.11 %\n",
      " * 8 ARITH ops\n",
      "\n",
      "- arith.constant:    8 occurrences  (f32: 6, i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "TF_LITE_MODEL = './mnist.tflite'  # 要產生的 TF Lite 檔名\n",
    "SAVE_KERAS_MODEL = True  # 是否儲存 Keras 原始模型\n",
    "import autokeras as ak\n",
    "import tensorflow as tf\n",
    "# 訓練 AutoKeras 模型\n",
    "clf = ak.ImageClassifier(max_trials=1, overwrite=True)\n",
    "clf.fit(x_train, y_train, epochs=20)\n",
    "# 用測試集評估模型\n",
    "loss, accuracy = clf.evaluate(x_test, y_test)\n",
    "print(f'\\nPrediction loss: {loss:.3f}, accurcy: {accuracy*100:.3f}%\\n')\n",
    "# 匯出 Keras 模型\n",
    "model = clf.export_model()\n",
    "model.summary()\n",
    "# 儲存 Keras 模型\n",
    "if SAVE_KERAS_MODEL:\n",
    "    model.save('./mnist_model')\n",
    "# 將模型轉為 TF Lite 格式\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# 你也可以讀取已儲存的 Keras 模型來轉換：\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model('./mnist_model')\n",
    "tflite_model = converter.convert()\n",
    "# 儲存 TF Lite 模型\n",
    "with open(TF_LITE_MODEL, 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
